{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d1c9a97-24e3-4d34-8e79-3acfe1e1a91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "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  ········\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "# Set your Groq API key\n",
    "if \"GROQ_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Groq API key \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f203de75-9263-45c3-bb88-20f6c3f978eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd be happy to help summarize text for you. Please provide the text you'd like me to summarize, and let me know what kind of summary you're looking for (e.g. brief summary, main points, key takeaways, etc.).\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Initialize the LLaMA-3 model\n",
    "llm = ChatGroq(\n",
    "    model=\"llama3-8b-8192\",  # You can also use \"llama3-70b-8192\" for a larger model\n",
    "    temperature=0,           # Low temperature for deterministic output\n",
    "    max_tokens=500           # Limit the output length\n",
    ")\n",
    "\n",
    "# Test the model with a simple prompt\n",
    "response = llm.invoke(\"Hello, can you summarize text?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87c76cf5-8af7-4980-904d-c0c315d77ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Define the summarization prompt\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Summarize the following text in a concise manner:\\n\\n{input_text}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ada1b179-0ee3-4cd3-b9dc-d0fbb88abc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Create the summarization chain\n",
    "summarization_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62a58ae8-887e-44a7-8b74-42baf0b9ba88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "The speaker describes their partner as a source of joy, calm, and beauty in their life. They bring warmth and light to even the darkest days, and their presence makes ordinary moments feel special. The speaker finds comfort and peace in their partner's company, and values their unwavering support and kindness. They consider their partner not just their girlfriend, but their best friend, safe space, and greatest adventure.\n"
     ]
    }
   ],
   "source": [
    "# Sample text to summarize\n",
    "text_to_summarize = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Run the summarization\n",
    "summary = summarization_chain.run(input_text=text_to_summarize)\n",
    "print(\"Summary:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5bca0f-49f7-486a-b8e0-0f1a71cbec62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
